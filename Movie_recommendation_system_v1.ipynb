{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0869b3",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a7a8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\muyan\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\muyan\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\muyan\\anaconda3\\lib\\site-packages (3.7)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "     -------------------------------------- 82.7/82.7 kB 421.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi>=2023.7.22\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "     ------------------------------------ 166.4/166.4 kB 624.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kaggle) (1.26.13)\n",
      "Requirement already satisfied: bleach in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from bleach->kaggle) (22.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105789 sha256=7a5ea3e5b9eb96ab3a56901f69fb9b5720b77ba4fd032eb8e49da2a7807a5ab7\n",
      "  Stored in directory: c:\\users\\muyan\\appdata\\local\\pip\\cache\\wheels\\0b\\74\\1d\\150587ee43d443adecd6ab02f22d569778bdd303377907a9ac\n",
      "Successfully built kaggle\n",
      "Installing collected packages: certifi, kaggle\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "Successfully installed certifi-2025.1.31 kaggle-1.6.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.27 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.27 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install pandas scikit-learn nltk kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d940208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ee7d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.8-py3-none-any.whl (55 kB)\n",
      "     -------------------------------------- 55.2/55.2 kB 408.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kagglehub) (4.64.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kagglehub) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from kagglehub) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\muyan\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\muyan\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1742c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ahsanaseer/top-rated-tmdb-movies-10k?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1.43M/1.43M [00:03<00:00, 482kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset: ['top10K-TMDB-movies.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Drama,Crime</td>\n",
       "      <td>en</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>94.075</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>8.7</td>\n",
       "      <td>21862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19404</td>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "      <td>hi</td>\n",
       "      <td>Raj is a rich, carefree, happy-go-lucky second...</td>\n",
       "      <td>25.408</td>\n",
       "      <td>1995-10-19</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Drama,Crime</td>\n",
       "      <td>en</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>90.585</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>8.7</td>\n",
       "      <td>16280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>Drama,History,War</td>\n",
       "      <td>en</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>44.761</td>\n",
       "      <td>1993-12-15</td>\n",
       "      <td>8.6</td>\n",
       "      <td>12959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>Drama,Crime</td>\n",
       "      <td>en</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>57.749</td>\n",
       "      <td>1974-12-20</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        title                 genre original_language  \\\n",
       "0    278     The Shawshank Redemption           Drama,Crime                en   \n",
       "1  19404  Dilwale Dulhania Le Jayenge  Comedy,Drama,Romance                hi   \n",
       "2    238                The Godfather           Drama,Crime                en   \n",
       "3    424             Schindler's List     Drama,History,War                en   \n",
       "4    240       The Godfather: Part II           Drama,Crime                en   \n",
       "\n",
       "                                            overview  popularity release_date  \\\n",
       "0  Framed in the 1940s for the double murder of h...      94.075   1994-09-23   \n",
       "1  Raj is a rich, carefree, happy-go-lucky second...      25.408   1995-10-19   \n",
       "2  Spanning the years 1945 to 1955, a chronicle o...      90.585   1972-03-14   \n",
       "3  The true story of how businessman Oskar Schind...      44.761   1993-12-15   \n",
       "4  In the continuing saga of the Corleone crime f...      57.749   1974-12-20   \n",
       "\n",
       "   vote_average  vote_count  \n",
       "0           8.7       21862  \n",
       "1           8.7        3731  \n",
       "2           8.7       16280  \n",
       "3           8.6       12959  \n",
       "4           8.6        9811  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"ahsanaseer/top-rated-tmdb-movies-10k\")\n",
    "\n",
    "# List the files in the downloaded directory\n",
    "files = os.listdir(path)\n",
    "print(\"Files in dataset:\", files)\n",
    "\n",
    "# Load the dataset (assuming it's a CSV file)\n",
    "csv_file = [f for f in files if f.endswith('.csv')][0]  # Get the first CSV file\n",
    "movies = pd.read_csv(os.path.join(path, csv_file))\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "movies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb100a11",
   "metadata": {},
   "source": [
    "## Data Inspection and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d62494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 10000 non-null  int64  \n",
      " 1   title              10000 non-null  object \n",
      " 2   genre              9997 non-null   object \n",
      " 3   original_language  10000 non-null  object \n",
      " 4   overview           9987 non-null   object \n",
      " 5   popularity         10000 non-null  float64\n",
      " 6   release_date       10000 non-null  object \n",
      " 7   vote_average       10000 non-null  float64\n",
      " 8   vote_count         10000 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 703.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19404</td>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>Raj is a rich, carefree, happy-go-lucky second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        title  \\\n",
       "0    278     The Shawshank Redemption   \n",
       "1  19404  Dilwale Dulhania Le Jayenge   \n",
       "2    238                The Godfather   \n",
       "3    424             Schindler's List   \n",
       "4    240       The Godfather: Part II   \n",
       "\n",
       "                                                tags  \n",
       "0  Framed in the 1940s for the double murder of h...  \n",
       "1  Raj is a rich, carefree, happy-go-lucky second...  \n",
       "2  Spanning the years 1945 to 1955, a chronicle o...  \n",
       "3  The true story of how businessman Oskar Schind...  \n",
       "4  In the continuing saga of the Corleone crime f...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data exploration\n",
    "movies.describe()\n",
    "movies.info()\n",
    "movies.isnull().sum()\n",
    "\n",
    "# Feature selection\n",
    "movies = movies[['id', 'title', 'overview', 'genre']]\n",
    "movies.head(5)\n",
    "\n",
    "# Create a 'tags' column\n",
    "movies['tags'] = movies['overview'] + movies['genre']\n",
    "movies.head(5)\n",
    "\n",
    "# Drop 'overview' and 'genre' columns\n",
    "new_data = movies.drop(columns=['overview', 'genre'])\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57dd975",
   "metadata": {},
   "source": [
    "## Text Cleaning (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a4e8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\muyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73775e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\muyan\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0a466c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\muyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\muyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\muyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                tags  \\\n",
      "0  Framed in the 1940s for the double murder of h...   \n",
      "1  Raj is a rich, carefree, happy-go-lucky second...   \n",
      "2  Spanning the years 1945 to 1955, a chronicle o...   \n",
      "3  The true story of how businessman Oskar Schind...   \n",
      "4  In the continuing saga of the Corleone crime f...   \n",
      "\n",
      "                                          tags_clean  \n",
      "0  framed 1940s double murder wife lover upstandi...  \n",
      "1  raj rich carefree happygolucky second generati...  \n",
      "2  spanning year 1945 1955 chronicle fictional it...  \n",
      "3  true story businessman oskar schindler saved t...  \n",
      "4  continuing saga corleone crime family young vi...  \n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stopwords and lemmatizer for efficiency\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function for cleaning the text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Return an empty string instead of None to avoid errors\n",
    "\n",
    "    # Convert to lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\d]', '', text)\n",
    "\n",
    "    # Tokenize and remove stop words\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Rejoin the words back together\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'tags' column\n",
    "new_data['tags_clean'] = new_data['tags'].apply(clean_text)\n",
    "\n",
    "# Verify the new column\n",
    "print(new_data[['tags', 'tags_clean']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463ad94",
   "metadata": {},
   "source": [
    "##  Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc433b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer to the 'tags_clean' column\n",
    "cv = CountVectorizer(max_features=10000, stop_words='english')\n",
    "\n",
    "# Transform the text data\n",
    "vector = cv.fit_transform(new_data['tags_clean'].values.astype('U')).toarray()\n",
    "\n",
    "# Show the shape of the vectorized data\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b75fac",
   "metadata": {},
   "source": [
    "## Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db17e0ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.03175003 0.02993422 ... 0.0862796  0.09274778 0.03745029]\n",
      " [0.03175003 1.         0.05892557 ... 0.         0.         0.        ]\n",
      " [0.02993422 0.05892557 1.         ... 0.         0.04303315 0.0347524 ]\n",
      " ...\n",
      " [0.0862796  0.         0.         ... 1.         0.         0.        ]\n",
      " [0.09274778 0.         0.04303315 ... 0.         1.         0.        ]\n",
      " [0.03745029 0.         0.0347524  ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(vector)\n",
    "\n",
    "# Verify the similarity array\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afc728",
   "metadata": {},
   "source": [
    "## Movie Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d8bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron Man 2\n",
      "Banana\n",
      "The New Mutants\n",
      "Time Trap\n",
      "The Disappearance of Alice Creed\n"
     ]
    }
   ],
   "source": [
    "# Define the recommend function\n",
    "def recommend(movie_title):\n",
    "    index = new_data[new_data['title'] == movie_title].index[0]\n",
    "    distance = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda vector: vector[1])\n",
    "    for i in distance[1:6]:  # Skipping the first result as it's the movie itself\n",
    "        print(new_data.iloc[i[0]]['title'])\n",
    "\n",
    "# Test the recommendation system with a movie title\n",
    "recommend(\"Iron Man\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a6749",
   "metadata": {},
   "source": [
    "## Save the Data and Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a94120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new_data and similarity matrices to disk\n",
    "pickle.dump(new_data, open('movies_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('similarity.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6347972",
   "metadata": {},
   "source": [
    "## Load and Test Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb811156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                        title  \\\n",
      "0    278     The Shawshank Redemption   \n",
      "1  19404  Dilwale Dulhania Le Jayenge   \n",
      "2    238                The Godfather   \n",
      "3    424             Schindler's List   \n",
      "4    240       The Godfather: Part II   \n",
      "\n",
      "                                                tags  \\\n",
      "0  Framed in the 1940s for the double murder of h...   \n",
      "1  Raj is a rich, carefree, happy-go-lucky second...   \n",
      "2  Spanning the years 1945 to 1955, a chronicle o...   \n",
      "3  The true story of how businessman Oskar Schind...   \n",
      "4  In the continuing saga of the Corleone crime f...   \n",
      "\n",
      "                                          tags_clean  \n",
      "0  framed 1940s double murder wife lover upstandi...  \n",
      "1  raj rich carefree happygolucky second generati...  \n",
      "2  spanning year 1945 1955 chronicle fictional it...  \n",
      "3  true story businessman oskar schindler saved t...  \n",
      "4  continuing saga corleone crime family young vi...  \n"
     ]
    }
   ],
   "source": [
    "# Load the saved data\n",
    "movies_list = pickle.load(open('movies_list.pkl', 'rb'))\n",
    "similarity = pickle.load(open('similarity.pkl', 'rb'))\n",
    "\n",
    "# Verify the loaded data\n",
    "print(movies_list.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08726c",
   "metadata": {},
   "source": [
    "## Download Files from Jupyter (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4293eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: C:\\Users\\muyan\\OneDrive - UBC\\School\\DS\\Machine learning\\Movie Recommendation System\\similarity_copy.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save to a file (if running on Jupyter)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Save in the current working directory\n",
    "shutil.copy('similarity.pkl', 'similarity_copy.pkl')\n",
    "\n",
    "# OR Save to a specific folder (e.g., Downloads)\n",
    "import os\n",
    "destination = os.path.join(os.getcwd(), 'similarity_copy.pkl')  # Save in the current directory\n",
    "shutil.copy('similarity.pkl', destination)\n",
    "\n",
    "print(f\"File saved to: {destination}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
